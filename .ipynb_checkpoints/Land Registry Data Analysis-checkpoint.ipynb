{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Land Reg </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> What areas that I can afford now, have posted the best returns for the past 10 years? </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Variables </center> \n",
    "\n",
    "<i>area</i> refers to the options for area selection present in the postcode data. <p>The options are listed in order of descending size:\n",
    "        <ul>\n",
    "            <li><i>county_name</i></li>\n",
    "            <li><i>town/city</i></li>\n",
    "            <li><i>ward_name</i></li>\n",
    "            <li><i>postcode</i></li>\n",
    "            <li><i>MSOA</i></li>\n",
    "            <li><i>LSOA</i></li>\n",
    "        </ul>\n",
    "\n",
    "The further down the list you go, the more targeted the area. \n",
    "\n",
    "<i>target</i> is the metric to be compared in all future functions. <p>The options are:\n",
    "        <ul>\n",
    "            <li><i>pct_change</i> - Percentage Change</li>\n",
    "            <li><i>price_diff</i> - Difference in Price year on year</li>\n",
    "            <li><i>price</i> - House Price</li>\n",
    "        </ul>\n",
    "        \n",
    "<i>year_min</i> & <i>year_max</i> are variables that set the range future functions will search and compare.<p>\n",
    "<i>budget_min</i> & <i>budget_max</i> sets your budget for future functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'target' (str)\n",
      "Stored 'area' (str)\n",
      "Stored 'year_min' (int)\n",
      "Stored 'year_max' (int)\n",
      "Stored 'budget_min' (int)\n",
      "Stored 'budget_max' (int)\n"
     ]
    }
   ],
   "source": [
    "target = 'pct_change'\n",
    "area = 'MSOA'\n",
    "\n",
    "year_min = 2000\n",
    "year_max = 2020\n",
    "budget_min = 200000\n",
    "budget_max = 350000\n",
    "property_type_dict = {\"D\": 'Detached', \"F\": \"Flat\", 'S':'Semi', 'T': \"Terrace\"}\n",
    "\n",
    "\n",
    "%store target\n",
    "%store area\n",
    "%store year_min\n",
    "%store year_max\n",
    "%store budget_min\n",
    "%store budget_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import math\n",
    "import os.path\n",
    "\n",
    "from datetime import datetime as dt\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "pd.set_option(\"display.max_rows\", 400000)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, TheilSenRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import plotly as py\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "\n",
    "font = {'family' : 'arial',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 18}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not find all_properties_and_postcodes.csv\n"
     ]
    }
   ],
   "source": [
    "file_list = ['all_properties_and_postcodes.csv','entire_period_filtered.csv', 'filtered_df.csv']\n",
    "\n",
    "file_check = True\n",
    "\n",
    "for file in file_list:\n",
    "    if os.path.isfile(file):\n",
    "        print (f'Found {file}')\n",
    "    else:\n",
    "        file_check = False\n",
    "        print (f\"Did not find {file}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV not found. Running notebook.\n",
      "Variables\n",
      "Target: pct_change\n",
      "area: MSOA\n",
      "year_min: 2000\n",
      "year_max: 2020\n",
      "budget_min: 200000\n",
      "budget_max: 350000 \n",
      "\n",
      "\n",
      "\n",
      "-------- Importing csv Data--------\n",
      "Read Property Csv\n",
      "Read Postcode Csv \n",
      "\n",
      "\n",
      "\n",
      "-------- Cleaning Data--------\n",
      "Dropped Columns\n",
      "Removed Non-Residental Sale Data\n",
      "Converted Prices To Integers\n",
      "Removed Outliers\n",
      "Converted Date_Sold\n",
      "Converted Year\n",
      "Datetime Objects Created\n",
      "Converted Postcodes\n",
      "Removed Nan Values\n",
      "Created Address Column\n",
      "Encoded Categorical Variables\n",
      "Dropped Address Columns\n",
      "Reset Index \n",
      "\n",
      "\n",
      "\n",
      "--------Merging Postcode And Property Data--------\n",
      "Merged Dataframes\n",
      "Saving all_properties_and_postcodes to csv\n",
      "Saved all_properties_and_postcodes \n",
      "\n",
      "\n",
      "\n",
      "--------Starting Filtering--------\n",
      "Saved Filtered_Df \n",
      "\n",
      "\n",
      "\n",
      "--------Starting Groupby--------\n",
      "Entire_Period_Filtered Dataframe Created\n",
      "Saved Entire_Period_Filtered \n",
      "\n",
      "properties_and_postcodes read\n",
      "filtered_df read\n",
      "entire_period_filtered read \n",
      "\n",
      "Recasting date strings to datetime\n",
      "All dates are now datetime objects \n",
      "\n"
     ]
    }
   ],
   "source": [
    "if file_check:\n",
    "    print('Reading all_properties_and_postcodes.csv')\n",
    "    all_properties_and_postcodes = pd.read_csv('all_properties_and_postcodes.csv', low_memory=False)\n",
    "    \n",
    "    print('Reading filtered_df.csv')\n",
    "    filtered_df = pd.read_csv('filtered_df.csv', low_memory=False)\n",
    "    \n",
    "    print('Reading entire_period_filtered.csv')\n",
    "    entire_period_filtered = pd.read_csv('entire_period_filtered.csv', low_memory=False)\n",
    "    \n",
    "else:\n",
    "    print('CSV not found. Running notebook.')\n",
    "    %run '/Users/nathanprice/Dropbox/Python/Land-Reg-Data-Analysis/Read & Filter.ipynb'\n",
    "    \n",
    "    all_properties_and_postcodes = pd.read_csv('all_properties_and_postcodes.csv', low_memory=False)\n",
    "    print ('properties_and_postcodes read')\n",
    "    filtered_df = pd.read_csv('filtered_df.csv', low_memory=False)\n",
    "    print ('filtered_df read')\n",
    "    entire_period_filtered = pd.read_csv('entire_period_filtered.csv', low_memory=False)\n",
    "    print ('entire_period_filtered read \\n')\n",
    "    \n",
    "    \n",
    "print ('Recasting date strings to datetime')\n",
    "all_properties_and_postcodes['date_sold'] = pd.to_datetime(all_properties_and_postcodes['date_sold'], format='%Y-%m-%d %H:%M')\n",
    "filtered_df['date_sold'] = pd.to_datetime(filtered_df['date_sold'], format='%Y-%m-%d %H:%M')\n",
    "entire_period_filtered['year_sold_min'] = pd.to_datetime(entire_period_filtered['year_sold_min'], format='%Y-%m-%d %H:%M')\n",
    "entire_period_filtered['year_sold_max'] = pd.to_datetime(entire_period_filtered['year_sold_max'], format='%Y-%m-%d %H:%M')\n",
    "print ('All dates are now datetime objects \\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### within_budget_function\n",
    "\n",
    "Due to the need to keep slicing various sections of the data, rather than rewrite this everytime I needed a new slice within the budget & years this does it in much less code.<br>Takes one argument, a dataframe to be filtered. <br> Returns the filtered dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def within_budget_function(df):\n",
    "    return df.loc[(df['price'] >= budget_min) & (df['price'] <= budget_max)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create_grid_cords\n",
    "\n",
    "My solution to being able to automatically create the correct number of subplots for the amount of plots being created. <br>\n",
    "Takes a single argument, top_n. top_n is the amount of total plots needed to be created. <br>\n",
    "Returns a list of coordinates for rows = top_n / 2 and cols = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grid_cords(top_n):\n",
    "    \"\"\"When given the top_n, returns a list of subplot coordinates for top_n amount of plots\"\"\"\n",
    "    \n",
    "    # Creates a list of values at steps of 0.5 from 1 to the asbolute value of (top_n + 2) // 2\n",
    "    n1 = np.arange(start = 1,\n",
    "                   stop = (top_n + 2) // 2,\n",
    "                   step = 0.5)\n",
    "\n",
    "\n",
    "    # math.floor rounds values down so 1.0 and 1.5 become 1. This gives us a list of 1, 1, 2, 2 etc.\n",
    "    n1 = [math.floor(x) for x in n1]\n",
    "\n",
    "    # creates a single list of [1, 2] top_n many times\n",
    "    n2 = list(range(1, 3)) * (top_n)\n",
    "\n",
    "    # runs across both lists and just returns each iterative value\n",
    "    cords_list = [[x, y] for (x, y) in zip(n1, n2)]\n",
    "    return cords_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1], [1, 2], [2, 1], [2, 2], [3, 1], [3, 2], [4, 1], [4, 2]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_grid_cords(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all_properties_and_postcodes\n",
    "\n",
    "<i>all_properties_and_postcodes</i> is a dataframe containing all the land registry data merged with the postcode data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>price</th>\n",
       "      <th>postcode</th>\n",
       "      <th>property_type</th>\n",
       "      <th>town/city</th>\n",
       "      <th>date_sold</th>\n",
       "      <th>year_sold</th>\n",
       "      <th>address</th>\n",
       "      <th>new</th>\n",
       "      <th>freehold</th>\n",
       "      <th>county_name</th>\n",
       "      <th>ward_name</th>\n",
       "      <th>LSOA</th>\n",
       "      <th>MSOA</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5111593</td>\n",
       "      <td>177000</td>\n",
       "      <td>AL10 0AB</td>\n",
       "      <td>S</td>\n",
       "      <td>HATFIELD</td>\n",
       "      <td>2003-10-10</td>\n",
       "      <td>2003</td>\n",
       "      <td>al100ablongmead01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hertfordshire</td>\n",
       "      <td>Hatfield Central</td>\n",
       "      <td>WelwynHatfield010F</td>\n",
       "      <td>WelwynHatfield010</td>\n",
       "      <td>-0.223341</td>\n",
       "      <td>51.773122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13723396</td>\n",
       "      <td>240000</td>\n",
       "      <td>AL10 0AB</td>\n",
       "      <td>T</td>\n",
       "      <td>HATFIELD</td>\n",
       "      <td>2014-01-31</td>\n",
       "      <td>2014</td>\n",
       "      <td>al100ablongmead017</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hertfordshire</td>\n",
       "      <td>Hatfield Central</td>\n",
       "      <td>WelwynHatfield010F</td>\n",
       "      <td>WelwynHatfield010</td>\n",
       "      <td>-0.223341</td>\n",
       "      <td>51.773122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18617676</td>\n",
       "      <td>360000</td>\n",
       "      <td>AL10 0AB</td>\n",
       "      <td>T</td>\n",
       "      <td>HATFIELD</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>2019</td>\n",
       "      <td>al100ablongmead017</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hertfordshire</td>\n",
       "      <td>Hatfield Central</td>\n",
       "      <td>WelwynHatfield010F</td>\n",
       "      <td>WelwynHatfield010</td>\n",
       "      <td>-0.223341</td>\n",
       "      <td>51.773122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13080928</td>\n",
       "      <td>220000</td>\n",
       "      <td>AL10 0AB</td>\n",
       "      <td>T</td>\n",
       "      <td>HATFIELD</td>\n",
       "      <td>2013-01-24</td>\n",
       "      <td>2013</td>\n",
       "      <td>al100ablongmead019</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hertfordshire</td>\n",
       "      <td>Hatfield Central</td>\n",
       "      <td>WelwynHatfield010F</td>\n",
       "      <td>WelwynHatfield010</td>\n",
       "      <td>-0.223341</td>\n",
       "      <td>51.773122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5928728</td>\n",
       "      <td>185000</td>\n",
       "      <td>AL10 0AB</td>\n",
       "      <td>T</td>\n",
       "      <td>HATFIELD</td>\n",
       "      <td>2004-09-06</td>\n",
       "      <td>2004</td>\n",
       "      <td>al100ablongmead019</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hertfordshire</td>\n",
       "      <td>Hatfield Central</td>\n",
       "      <td>WelwynHatfield010F</td>\n",
       "      <td>WelwynHatfield010</td>\n",
       "      <td>-0.223341</td>\n",
       "      <td>51.773122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   price  postcode property_type town/city  date_sold  year_sold             address  new  freehold    county_name         ward_name                LSOA               MSOA  Longitude   Latitude\n",
       "0     5111593  177000  AL10 0AB             S  HATFIELD 2003-10-10       2003   al100ablongmead01    0         1  Hertfordshire  Hatfield Central  WelwynHatfield010F  WelwynHatfield010  -0.223341  51.773122\n",
       "1    13723396  240000  AL10 0AB             T  HATFIELD 2014-01-31       2014  al100ablongmead017    0         1  Hertfordshire  Hatfield Central  WelwynHatfield010F  WelwynHatfield010  -0.223341  51.773122\n",
       "2    18617676  360000  AL10 0AB             T  HATFIELD 2019-10-11       2019  al100ablongmead017    0         1  Hertfordshire  Hatfield Central  WelwynHatfield010F  WelwynHatfield010  -0.223341  51.773122\n",
       "3    13080928  220000  AL10 0AB             T  HATFIELD 2013-01-24       2013  al100ablongmead019    0         1  Hertfordshire  Hatfield Central  WelwynHatfield010F  WelwynHatfield010  -0.223341  51.773122\n",
       "4     5928728  185000  AL10 0AB             T  HATFIELD 2004-09-06       2004  al100ablongmead019    0         1  Hertfordshire  Hatfield Central  WelwynHatfield010F  WelwynHatfield010  -0.223341  51.773122"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_properties_and_postcodes.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-83ff0806920d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfigure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_properties_and_postcodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkde\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_properties_and_postcodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_properties_and_postcodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Distribution of house prices within all_properties_and_postcodes'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/seaborn/distributions.py\u001b[0m in \u001b[0;36mdisplot\u001b[0;34m(data, x, y, hue, row, col, weights, kind, rug, rug_kws, log_scale, legend, palette, hue_order, hue_norm, color, col_wrap, row_order, col_order, height, aspect, facet_kws, **kwargs)\u001b[0m\n\u001b[1;32m   2146\u001b[0m     p = _DistributionFacetPlotter(\n\u001b[1;32m   2147\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2148\u001b[0;31m         \u001b[0mvariables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_DistributionFacetPlotter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_semantics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2149\u001b[0m     )\n\u001b[1;32m   2150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/seaborn/distributions.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, variables)\u001b[0m\n\u001b[1;32m    106\u001b[0m     ):\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/seaborn/_core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, variables)\u001b[0m\n\u001b[1;32m    602\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_semantic_mappings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/seaborn/_core.py\u001b[0m in \u001b[0;36massign_variables\u001b[0;34m(self, data, variables)\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"wide\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m             plot_data, variables = self._assign_variables_wideform(\n\u001b[0;32m--> 663\u001b[0;31m                 \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m             )\n\u001b[1;32m    665\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/seaborn/_core.py\u001b[0m in \u001b[0;36m_assign_variables_wideform\u001b[0;34m(self, data, **kwargs)\u001b[0m\n\u001b[1;32m    721\u001b[0m         flat = not any(\n\u001b[1;32m    722\u001b[0m             \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m         )\n\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/seaborn/_core.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    721\u001b[0m         flat = not any(\n\u001b[1;32m    722\u001b[0m             \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m         )\n\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/abc.py\u001b[0m in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_abc_register\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubclass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0m__instancecheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0;34m\"\"\"Override for isinstance(instance, cls).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_abc_instancecheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "figure = sns.displot(data=all_properties_and_postcodes['price'], kde=True, bins=50, height=8, aspect=1.5)\n",
    "plt.xlim(all_properties_and_postcodes['price'].min(), all_properties_and_postcodes['price'].max())\n",
    "plt.title('Distribution of house prices within all_properties_and_postcodes'.title())\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = all_properties_and_postcodes.loc[all_properties_and_postcodes['year_sold'] > year_min].copy()\n",
    "cdf = cdf.groupby('price')['address'].count().reset_index()\n",
    "cdf = cdf.rename(columns={'address': 'count'})\n",
    "cdf_total = cdf['count'].sum()\n",
    "cdf['running_total'] = cdf['count'].cumsum()\n",
    "cdf['percentage'] = cdf['running_total'] / cdf_total * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_min = float (cdf['percentage'].loc[cdf['price'] == budget_min])\n",
    "pct_max = float (cdf['percentage'].loc[cdf['price'] == budget_max])\n",
    "\n",
    "print (f\"{int(pct_max - pct_min)}% of houses from {year_min} to {year_max} are in your budget of £{str(budget_min)[0:3]},{str(budget_min)[3:]} to £{str(budget_max)[0:3]},{str(budget_max)[3:]}\")\n",
    "\n",
    "cdf.plot(x='price', y='percentage', kind='line', figsize=(10, 8), legend=False, style='r')\n",
    "plt.title('Cumulative Percentage of properties by value'.title(), y = 1.01, fontsize=20)\n",
    "plt.ylabel('percntage of houses'.title(), labelpad=15)\n",
    "plt.xlabel('House price'.title(), labelpad=15)\n",
    "plt.xticks(rotation=25)\n",
    "plt.axvline(x=budget_min, color='blue', linestyle='--')\n",
    "plt.axvline(x=budget_max, color='darkblue', linestyle='--')\n",
    "# plt.axhline(y=pct_min, color='g', linestyle='--')\n",
    "# plt.axhline(y=pct_max, color='b', linestyle='--')\n",
    "plt.legend(['Cumulative Percentage', 'Minimum Budget', 'Maximum Budget'])\n",
    "plt.show();\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage of Affordable Properties per County\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_total = all_properties_and_postcodes.groupby(['county_name']).agg(total=('price', 'count')).reset_index()\n",
    "\n",
    "df_within_budget = within_budget_function(all_properties_and_postcodes)\n",
    "\n",
    "df_within_budget = df_within_budget.groupby(['county_name']).agg(count=('price', 'count')).reset_index()\n",
    "\n",
    "compare_counts = df_within_budget.merge(area_total, on='county_name')\n",
    "\n",
    "compare_counts['percentage'] = compare_counts['count'] / compare_counts['total'] * 100\n",
    "\n",
    "compare_counts = compare_counts.head(15)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_figs = go.Figure()\n",
    "percentage_figs = percentage_figs.add_trace(go.Pie(labels=compare_counts['county_name'], values=compare_counts['count'].loc[compare_counts['percentage'] >= 20], name='butt'))#,row=1, col=2)\n",
    "percentage_figs = percentage_figs.update_layout(title_text='Affordable Houses as Percentage of total available'.title())\n",
    "percentage_figs.show()\n",
    "\n",
    "bar_figs = go.Figure()\n",
    "bar_figs = bar_figs.add_trace(go.Bar(y=compare_counts['county_name'], x=compare_counts['percentage'].loc[compare_counts['percentage'] >= 25].sort_values(ascending=False), showlegend=False, orientation='h'))#, row=1, col=1)\n",
    "bar_figs = bar_figs.update_layout(title_text='Affordable Houses as Percentage total houses within each Ward'.title())\n",
    "\n",
    "\n",
    "bar_figs.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>filtered_df</b> is a dataframe containing a subsection of properties deemed affordable. \n",
    "\n",
    "<ul>\n",
    "    <li>Only contains properties that were within budget for the past 5 years </li> \n",
    "    <li>Only contains properties that were sold more than once</li>\n",
    "    <li>Only contains properties that have a single property type</li>\n",
    "    <li>Does a final sweep to ensure all properties are within a range of the budget </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = sns.displot(data=filtered_df['price'], kde=True, bins=50, height=8, aspect=1.5)\n",
    "plt.xlim(filtered_df['price'].min(), filtered_df['price'].max())\n",
    "plt.title('Distribution of house prices within filtered_df'.title())\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### entire_period_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entire_period_filtered.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>entire_period_filtered</b> is a dataframe that has a single entry for each address. <br> It takes the first sale and the last sale and makes calculations between the two. But it does not have access to year-on-year data. \n",
    "\n",
    "<ul>\n",
    "    <li><b>year_diff</b></li> is the difference from the year of the first sale, to the year of the last sale.\n",
    "    <li><b>price_diff</b></li> is the difference in price from the first sale to the last sale \n",
    "    <li><b>price_change_per_year</b></li> is the average price change for each year.\n",
    "    <li><b>total_pct_change</b></li> is the absolute percantage change from the first sale to the last.\n",
    "    <li><b>pct_change_per_year</b></li> is the average percentage change for each year.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = sns.displot(data=entire_period_filtered['max_price'], kde=True, bins=50, height=8, aspect=1.5)\n",
    "plt.xlim(entire_period_filtered['max_price'].min(), entire_period_filtered['max_price'].max())\n",
    "plt.title('Distribution of house prices within entire_period_filtered'.title())\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find_best_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_area(dataset, target=target, area=area, n=15, min_n = 100, year_min=None, year_max=None):\n",
    "\n",
    "    list_of_areas_with_n_less_than_n = []\n",
    "\n",
    "    for location in list(dataset[area].unique()):\n",
    "        if len (dataset.loc[dataset[area] == location]) <= min_n:\n",
    "            list_of_areas_with_n_less_than_n.append(location)\n",
    "    \n",
    "    dataset = dataset.loc[~dataset[area].isin(list_of_areas_with_n_less_than_n)]\n",
    "\n",
    "    group = dataset.groupby([area, 'county_name'])[target].median().sort_values(ascending=False)\n",
    "    \n",
    "    group = group.reset_index().head(n)\n",
    "    \n",
    "    area_names = list (group[area].unique())\n",
    "    \n",
    "    entire_period_best_area_dataframe = dataset.loc[dataset[area].isin(area_names)]\n",
    "   \n",
    "    return group, area_names, entire_period_best_area_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>find_best_area</b> is a function to find the best n areas. \n",
    "<p>The areas are ordered by the median increase of the <b>target</b> variable.\n",
    "\n",
    "It will only use entries where there are more than <b>n</b> sales. \n",
    "\n",
    "It returns three objects:<br>\n",
    "<ul>    \n",
    "    <li>A dataframe that contains the median of the target dataset grouped by the specified area and county name.</li>\n",
    "    <li>A list of the best area names</li>\n",
    "    <li>A dataframe similar to <b>entire_period_filtered</b>, but only containing entries for the top n areas as found by the function.</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top N Areas\n",
    "\n",
    "Listed below are the best <b>area</b> names as created by the <b>find_best_area<b> function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_area, best_area_names, entire_period_best_area_dataframe = find_best_area(entire_period_filtered,\n",
    "                                                                               area=area,\n",
    "                                                                               target=target)\n",
    "\n",
    "best_area_names[:top_n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median Percentage Change by County / MSOA\n",
    "\n",
    "On the left is median percentage change by county, and on the right is MSOA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_area_counties_median = entire_period_best_area_dataframe.groupby('county_name')[target].median().reset_index()\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "\n",
    "fig_1 = best_area_counties_median.plot(kind='bar', x='county_name', y=target, ax=axes[0], rot=75, colormap='coolwarm', legend=False, title='County Name')\n",
    "fig_2 = best_area.plot(kind='bar', x=area, y=target, ax=axes[1], rot=75, colormap='coolwarm', legend=False, title='MSOA')\n",
    "\n",
    "fig.suptitle(f'Median total {target} for County & {area} from {year_min} to {year_max}'.replace(\"_\", \" \").title())\n",
    "\n",
    "fig_1.set_ylabel(target)\n",
    "fig_2.set_ylabel(target)\n",
    "\n",
    "fig_1.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "fig_2.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "\n",
    "\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### yearly_dataframe\n",
    "\n",
    "<b>yearly_dataframe</b> creates a dataframe that allows you to track the price changes by individual address year on year. \n",
    "\n",
    "It should be called on an un-modified/ungrouped dataset such as <b>filtered_df</b>.\n",
    "\n",
    "It returns a dataframe containing all indiviudal sales with the following new columns:\n",
    "<ul>\n",
    "    <li><b>prev_price</b></li> is the last recorded sale price\n",
    "    <li><b>price_diff</b></li> is the difference between the current sale and the last\n",
    "    <li><b>pct_change</b></li> is the percentage change between the current sale and the last\n",
    "    <li><b>prev_year</b></li> is the year of the previous sale\n",
    "    <li><b>year_diff</b></li> is the time difference between the current sale and the last\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yearly_dataframe(dataframe):\n",
    "    # Creates a yearly change groupby object that then gets reset into a dataframe\n",
    "    yearly_group = dataframe.groupby(['address','property_type', 'town/city', 'postcode', 'county_name', 'ward_name', 'MSOA', 'LSOA', 'year_sold', 'date_sold', 'price']).median()\n",
    "    yearly_group = yearly_group.reset_index()\n",
    "\n",
    "    # Creates a new column year-date sold\n",
    "    yearly_group['year_month_sold'] = yearly_group['date_sold'].apply(lambda x: x.strftime(\"%Y-%m\"))\n",
    "    yearly_group['year_month_sold'] = pd.to_datetime(yearly_group['year_month_sold'], format='%Y-%m')\n",
    "    \n",
    "    # Creates columns\n",
    "    yearly_group['prev_price'] = yearly_group.groupby('address')['price'].shift()\n",
    "    yearly_group['price_diff'] = yearly_group['price'] - yearly_group['prev_price']\n",
    "    yearly_group['pct_change'] = (((yearly_group['price'] - yearly_group['prev_price']) / yearly_group['prev_price']) * 100)\n",
    "    yearly_group['prev_year'] = yearly_group.groupby('address')['year_sold'].shift()\n",
    "    yearly_group['year_diff'] = yearly_group['year_sold'] - yearly_group['prev_year']\n",
    "\n",
    "    # Filters NaN values \n",
    "    yearly_group['prev_price'] = np.where(np.isnan(yearly_group['prev_price']), 0, yearly_group['prev_price'])\n",
    "    yearly_group['price_diff'] = np.where(np.isnan(yearly_group['price_diff']), 0, yearly_group['price_diff'])\n",
    "    yearly_group['prev_year'] = np.where(np.isnan(yearly_group['prev_year']), 0, yearly_group['prev_year'])\n",
    "    yearly_group['year_diff'] = np.where(np.isnan(yearly_group['year_diff']), 0, yearly_group['year_diff'])\n",
    "    yearly_group['pct_change'] = np.where(np.isnan(yearly_group['pct_change']), 0, yearly_group['pct_change'])\n",
    "\n",
    "    # Removes entries with a zero price diff or zero year diff\n",
    "    yearly_group = yearly_group.loc[(yearly_group['price_diff'] != 0) & (yearly_group['year_diff'] >= 1)]\n",
    "    \n",
    "    \n",
    "    \n",
    "    return yearly_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### best_areas_yearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_areas_yearly = yearly_dataframe(filtered_df[filtered_df[area].isin(best_area_names)])\n",
    "best_areas_yearly.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>best_areas_yearly</b> is a dataframe containing data for each sale for the best areas as defined by the <b>find_best_area</b> function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all_yearly_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_yearly_dataframe = yearly_dataframe(filtered_df)\n",
    "all_yearly_dataframe.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>all_yearly_dataframe</b> is a dataframe containing yearly data for <b>all</b> addresses across the entire country. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### National Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "national_affordable_medians = entire_period_filtered.groupby('county_name')[['pct_change', 'price_diff', 'year_diff', 'pct_change_per_year']].median().median().reset_index()\n",
    "\n",
    "\n",
    "national_affordable_medians = national_affordable_medians.rename(columns={'index': 'metric', 0: 'national_affordable_median'})\n",
    "national_affordable_medians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>national_affordable_medians</b> is a dataframe containing the median values for total percentage change, difference in first and last price, difference in first and last year sold, and rate of pct change for properties deemed 'affordable' across the country. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### performed_better\n",
    "<b>performed_better</b> is a function to compare the median values of specific areas against the national median for affordable properties. \n",
    "\n",
    "You can pass the location as a list and it will check against all those locations. The same can be done with addresses with the <b>address</b> argument. You must always pass the locations / addresses as a list. \n",
    "\n",
    "It returns a dataframe that is the <b>national_affordable_medians</b> dataframe merged with the comparison data. \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performed_better(locations,\n",
    "                     dataframe=entire_period_filtered,\n",
    "                     area=area, \n",
    "                     address=None):\n",
    "    \n",
    "    comparison_df = national_affordable_medians.copy()\n",
    "    \n",
    "    if address == None:\n",
    "        area_of_interest = dataframe.loc[dataframe[area].isin(locations)]\n",
    "    else:\n",
    "        area_of_interest = dataframe.loc[dataframe['address'].isin(address)]\n",
    "        area = 'address'\n",
    "        locations = address\n",
    "        \n",
    "    for location in locations:\n",
    "        \n",
    "        location_of_interest = area_of_interest.loc[area_of_interest[area] == location].groupby(area)[['pct_change', 'price_diff', 'year_diff', 'pct_change_per_year']].median().reset_index()\n",
    "        comparison_df[location] = [location_of_interest['pct_change'].item(), location_of_interest['price_diff'].item(), location_of_interest['year_diff'].item(), location_of_interest['pct_change_per_year'].item()]\n",
    "    \n",
    "    return comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison Against National Median\n",
    "\n",
    "The table below shows the median values for top N performing areas against the national median. \n",
    "\n",
    "<ul>\n",
    "    <li><b>pct_change</b></li>Total percentage change over the entire period\n",
    "    <li><b>price_diff</b></li>Median difference from the first sale to the last\n",
    "    <li><b>year_diff</b></li>The median years between house sales\n",
    "    <li><b>pct_change_per_year</b></li>Median percentage change each year for the entire period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df = performed_better(locations=best_area_names)\n",
    "comparison_df = comparison_df.set_index('metric')\n",
    "\n",
    "comparison_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### expo_subplots_for_area\n",
    "\n",
    "<b>expo_subplots_for_area</b> creates scatter plots and Exponential Moving Average values for areas passed to the function.\n",
    "\n",
    "Currently you have to change the <b>rows</b> and <b>cols</b> for the subplot manually in the function to match the <b>top_n</b> areas. \n",
    "\n",
    "It returns two objects:<br>\n",
    "<ul> \n",
    "    <b><li>figure</li></b> A pyplot figure containing the subplots.\n",
    "    <b><li>n_table</li></b> A dataframe containing the number of sales for each area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expo_subplots_for_area(dataframe=best_areas_yearly, target=target, area=area, ema_val=0.5, top_n=4):\n",
    "\n",
    "\n",
    "    year_min = dataframe['year_sold'].min()\n",
    "    year_max = dataframe['year_sold'].max()\n",
    "    \n",
    "    \n",
    "    n_table = pd.DataFrame(columns=[], index=['n'])\n",
    "    \n",
    "    area_list = list(dataframe[area].unique())[:top_n]\n",
    "    \n",
    "    # Created function to create appropriate grid cordinates given the top_n number of plots needed to be created\n",
    "    cords_list = create_grid_cords(top_n)\n",
    "\n",
    "#     Creates a figure and axes object.     \n",
    "    fig = make_subplots(rows=top_n // 2, cols=2, subplot_titles=area_list, shared_xaxes='all')\n",
    "\n",
    "    \n",
    "    for cord, location in zip(cords_list, area_list):\n",
    "        df = dataframe.loc[(dataframe[area] == location) \n",
    "                              & (dataframe['year_sold'] >= year_min) \n",
    "                              & (dataframe['year_sold'] <= year_max)].copy()\n",
    "        \n",
    "        df = df.groupby('year_month_sold')[target].median().reset_index()\n",
    "        \n",
    "        fig.add_trace(go.Scatter(x=df['year_month_sold'], y=df[target], mode='markers'),\n",
    "                     row=cord[0], col=cord[1])\n",
    "        \n",
    "        df['EMA_' + str(ema_val)] = df[target].ewm(alpha=ema_val, adjust=False).mean()\n",
    "        \n",
    "        fig.add_trace(go.Scatter(x=df['year_month_sold'], y=df['EMA_' + str(ema_val)], mode='lines', name='EMA'),\n",
    "                     row=cord[0], col=cord[1])\n",
    "        \n",
    "        n_table[location] = len(df)\n",
    "\n",
    "        \n",
    "    fig.update_layout(title_text=f\"{target} grouped by Month<br>EMA Val - {ema_val}\".title().replace(\"_\", \" \"))\n",
    "    fig.update_layout(showlegend=False)\n",
    "    fig.update_xaxes(nticks=15)\n",
    "    \n",
    "    return fig, n_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_areas_figure, n_table = expo_subplots_for_area(dataframe=best_areas_yearly,\n",
    "                                               target=target,\n",
    "                                              ema_val=0.2)\n",
    "\n",
    "n_table\n",
    "best_areas_figure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### poly_subplots_for_area\n",
    "\n",
    "<b>poly_subplots_for_area</b> creates scatter plots and a polynomial regression for areas passed to the function.\n",
    "\n",
    "Currently you have to change the <b>rows</b> and <b>cols</b> for the subplot manually in the function to match the <b>top_n</b> areas. \n",
    "\n",
    "It returns two objects:<br>\n",
    "<ul> \n",
    "    <b><li>figure</li></b> A pyplot figure containing the subplots.\n",
    "    <b><li>n_table</li></b> A dataframe containing the number of sales for each area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_subplots_for_area(dataframe=best_areas_yearly, target=target, area=area, top_n=6):\n",
    "\n",
    "\n",
    "    year_min = dataframe['year_sold'].min()\n",
    "    year_max = dataframe['year_sold'].max()\n",
    "    \n",
    "    \n",
    "    n_table = pd.DataFrame(columns=[], index=['n'])\n",
    "    \n",
    "    area_list = list(dataframe[area].unique())\n",
    "    \n",
    "    # Created function to create appropriate grid cordinates given the top_n number of plots needed to be created\n",
    "    cords_list = create_grid_cords(top_n)\n",
    "\n",
    "#     Creates a figure and axes object.     \n",
    "    fig = make_subplots(rows=(top_n // 2),\n",
    "                        cols=2,\n",
    "                        subplot_titles=area_list,\n",
    "                        shared_xaxes='all',\n",
    "                        print_grid=False)\n",
    "\n",
    "    # Iterates through the subplot grids, and the locations named in area_list\n",
    "    for cord, location in zip(cords_list, area_list):\n",
    "\n",
    "        #creates temporary dataframe containing only matched locations, and areas within the correct year range\n",
    "        df = dataframe.loc[(dataframe[area] == location) \n",
    "                              & (dataframe['year_sold'] >= year_min) \n",
    "                              & (dataframe['year_sold'] <= year_max)].copy()\n",
    "        \n",
    "        #groups the df by the year_month sold creating a single median entry for each month of the year\n",
    "        df = df.groupby('year_month_sold')[target].median().reset_index()\n",
    "        \n",
    "        #creates a new column converting the year_month_sold datetime value to a ordinal value to allow model creation\n",
    "        df['ord_dates'] = df['year_month_sold'].map(dt.toordinal)\n",
    "        \n",
    "        #variable creation for readability later\n",
    "        x_vals = df['ord_dates']\n",
    "        y_vals = df[target]\n",
    "        \n",
    "        #Adds a scatter trace to teh specified row, col subplot of all monthly sale information\n",
    "        fig.add_trace(go.Scatter(x=df['year_month_sold'],\n",
    "                                 y=y_vals,\n",
    "                                 mode='markers'),\n",
    "                     row=cord[0], col=cord[1])\n",
    "\n",
    "        #variable creation to values in the coming for loop\n",
    "        best_score = 0\n",
    "        best_i = 0\n",
    "        #iterates over a specified range to try different polynomial values to find the most accurate line\n",
    "        for i in range(20):\n",
    "            \n",
    "                    \n",
    "            #surpresses numpy warnings about model being incorrectly fit as it iterates over all posibilties\n",
    "            np.warnings.filterwarnings('ignore')\n",
    "            \n",
    "            #stolen from stackoverflow, not 100% sure what's happening\n",
    "            #From what I can tell it's similar to scikit and is fitting the data to a model with a polynomial, i\n",
    "            mymodel = np.poly1d(np.polyfit(x_vals,\n",
    "                                          y_vals,\n",
    "                                          i))\n",
    "            #creates an array of x values\n",
    "            myline = np.linspace(x_vals[0],\n",
    "                                 x_vals[len(x_vals) - 1])\n",
    "            \n",
    "            #returns r2 score of the mode\n",
    "            score = r2_score(y_vals, mymodel(x_vals))\n",
    "            \n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_i = i\n",
    "        \n",
    "        #refits the model with the best_i value found by the above for loop\n",
    "        mymodel = np.poly1d(np.polyfit(x_vals, y_vals, best_i))\n",
    "        \n",
    "        #this is key\n",
    "        #creates a new series of datetime values from the ordinal date values used in the numpy model\n",
    "        my_line_dates = pd.Series(myline.astype(int)).map(dt.fromordinal)\n",
    "        \n",
    "        #adds the polynomial line to the figure.\n",
    "        fig.add_trace(go.Scatter(x = my_line_dates,\n",
    "                                 y = mymodel(myline),\n",
    "                                 mode='lines'),\n",
    "                     row=cord[0], col=cord[1])       \n",
    "\n",
    "        \n",
    "        n_table[location] = len(df)\n",
    "\n",
    "    fig.update_layout(title_text=f\"{target} grouped by Month<br>With polynomial regression lines\".title().replace(\"_\", \" \"))\n",
    "    fig.update_layout(showlegend=False)\n",
    "    fig.update_xaxes(nticks=20)\n",
    "\n",
    "    \n",
    "    return fig, n_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_areas_figure, n_table = poly_subplots_for_area(dataframe=best_areas_yearly,\n",
    "                                               target=target)\n",
    "\n",
    "n_table\n",
    "best_areas_figure\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map of Best Affordable Areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_mapbox(best_areas_yearly, lat=\"Latitude\", lon=\"Longitude\", hover_name=\"address\", hover_data=[\"price\", \"ward_name\", 'MSOA', 'postcode'],\n",
    "                        color=area, size='price',\n",
    "                  color_continuous_scale=px.colors.cyclical.IceFire, zoom=6, height=1000, width=1000)\n",
    "fig.update_layout(mapbox_style=\"carto-positron\")\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create_process_control_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outputs and displays a process control chart. \n",
    "<ul>\n",
    "    <li>You should already have filtered the passed dataframe to only contain the subsection / area of interest, and time period / grouping of interest. </li>\n",
    "    <li>n_group is how many data points each point on the scatter will represent. </li>\n",
    "    <li>x_name is the name of the column being passed as the x axis. x_name has to be a datetime format.</li>\n",
    "    <li>y_name is the name of the column being passed as the y axis. Has to be numerical. </li>\n",
    "    <li>time interval is a time series / date offset value from the pandas datetime module. Defailt is 'BYS' - beginning of calendar year. </ul>\n",
    "    <li>You can specify a custom title by passing it as a string to the <b>title=</b> arugment.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotly_create_process_control_chart(dataframe, n_group, x_name, y_name, time_interval='BYS', title=False):\n",
    "    \n",
    "    # Organises data in chronological order \n",
    "    dataframe = dataframe.sort_values(x_name)\n",
    "\n",
    "    # Finds first and last date in the data\n",
    "    first_date = dataframe[x_name].min()\n",
    "    last_date = dataframe[x_name].max()\n",
    "\n",
    "    # Creates dataframe to be filled later\n",
    "    final_dataframe = pd.DataFrame(columns=[x_name, y_name])\n",
    "    \n",
    "    # For loop to create n_group length slices within the data\n",
    "    for i in range(n_group, len(dataframe), n_group):\n",
    "        df_slice = dataframe.iloc[i - n_group: i]\n",
    "\n",
    "        y_val = df_slice[y_name].median()\n",
    "        x_val = df_slice[x_name].min()\n",
    "\n",
    "        vals = pd.DataFrame([[x_val, y_val]], columns=list(final_dataframe.columns))\n",
    "\n",
    "        final_dataframe = final_dataframe.append(vals)\n",
    "\n",
    "    # Pandas date_range function used to pass dates to the for loop to create LCL, UCL and central lines\n",
    "    date_range = pd.date_range(start=first_date,\n",
    "                               end=last_date + relativedelta(years=1),\n",
    "                               freq=time_interval, closed=None)\n",
    "\n",
    "    # Creates plotly graph object     \n",
    "    fig = go.Figure()\n",
    "    # Adds a scatter trace to the graph object of the slices we created\n",
    "    fig.add_trace(go.Scatter(x=final_dataframe[x_name], y=final_dataframe[y_name], mode='lines+markers', name='Rolling Median House Price'))\n",
    "    \n",
    "    # Logic to loop through the date ranges to find the boundries for each of the lines\n",
    "    for n in range(1, len(list(date_range)), 1):\n",
    "        \n",
    "        # Try, except here to catch the index error.  \n",
    "        try:\n",
    "            \n",
    "            # Create a dataframe containing only information within the date boundries. \n",
    "            date_slice = dataframe[y_name].loc[(dataframe[x_name] > date_range[n - 1]) &\n",
    "                                         (dataframe[x_name] < date_range[n])]\n",
    "            \n",
    "            # Mean, STD, UCL and LCL\n",
    "            mean = date_slice.mean()\n",
    "            std = date_slice.std()\n",
    "            UCL = mean + (std * 3)\n",
    "            LCL = mean - (std * 3)\n",
    "            \n",
    "            # \n",
    "            # Adding the Central Line \n",
    "            fig.add_shape(type='line',\n",
    "                x0=date_range[n-1],\n",
    "                y0=mean,\n",
    "                x1=date_range[n],\n",
    "                y1=mean,\n",
    "                line=dict(\n",
    "                    color=\"Red\",\n",
    "                    width=1))\n",
    "\n",
    "            # Adding the Upper control line\n",
    "            fig.add_shape(type='line',\n",
    "                x0=date_range[n-1],\n",
    "                y0=UCL,\n",
    "                x1=date_range[n],\n",
    "                y1=UCL,\n",
    "                line=dict(\n",
    "                    color=\"Black\",\n",
    "                    width=3,\n",
    "                    dash=\"dot\"))\n",
    "\n",
    "            # Adding the Lower control line\n",
    "            fig.add_shape(type='line',\n",
    "                x0=date_range[n-1],\n",
    "                y0=LCL,\n",
    "                x1=date_range[n],\n",
    "                y1=LCL,\n",
    "                line=dict(\n",
    "                    color=\"Black\",\n",
    "                    width=3,\n",
    "                    dash=\"dot\"), name='LCL')\n",
    "        \n",
    "        except IndexError:\n",
    "            continue \n",
    "\n",
    "    fig.update_xaxes(nticks=20)\n",
    "    \n",
    "    if title:\n",
    "        fig.update_layout(title=title.replace(\"_\", \" \").title())\n",
    "    else:\n",
    "        fig.update_layout(title=f'{y_name} by {x_name}'.replace(\"_\", \" \").title())\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_create_process_control_chart(dataframe=best_areas_yearly, \n",
    "                             n_group=25, \n",
    "                             x_name='date_sold', \n",
    "                             y_name='price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_create_process_control_chart(dataframe=best_areas_yearly.groupby('year_month_sold')['price'].median().reset_index(), \n",
    "                             n_group=1, \n",
    "                             x_name='year_month_sold', \n",
    "                             y_name='price',\n",
    "                             title='Price by Year Month Sold for best_areas_yearly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_compare_scatter(dataframe, x_name, y_name, z_name, rolling_type='ema', ema_val=0.5, rolling_val=10, title=False):\n",
    "    \n",
    "    df = dataframe.groupby([x_name, z_name])[y_name].median().reset_index()\n",
    "    \n",
    "    figure = go.Figure()\n",
    "    figure.add_trace(go.Scatter(x=df[x_name],\n",
    "                                y=df[y_name],\n",
    "                                mode='markers',\n",
    "                                opacity=0.2,\n",
    "                                name='Sale Price'))\n",
    "    \n",
    "    for z in df[z_name].unique():\n",
    "        df_by_type = df.loc[df[z_name] == z].copy()\n",
    "        \n",
    "        if rolling_type == 'ema':\n",
    "            df_by_type['EMA_' + str(ema_val)] = df_by_type[y_name].ewm(alpha=ema_val, adjust=False).mean()\n",
    "\n",
    "\n",
    "            figure.add_trace(go.Scatter(x=df_by_type[x_name], \n",
    "                                        y=df_by_type['EMA_' + str(ema_val)], \n",
    "                                        name=property_type_dict[z],\n",
    "                                        mode='markers+lines'))\n",
    "\n",
    "            if title:\n",
    "                figure.update_layout(title=title.title())\n",
    "            else:\n",
    "                figure.update_layout(title=f'{y_name} by {x_name} for {z_name} with EMA - {ema_val}'.replace(\"_\", \" \").title())\n",
    "\n",
    "\n",
    "        \n",
    "        if rolling_type == 'avg':\n",
    "            df_by_type['rolling'] = df_by_type[y_name].rolling(rolling_val).mean()\n",
    "\n",
    "\n",
    "            figure.add_trace(go.Scatter(x=df_by_type[x_name], \n",
    "                                        y=df_by_type['rolling'], \n",
    "                                        name=property_type_dict[z],\n",
    "                                        mode='markers+lines'))\n",
    "\n",
    "        if title:\n",
    "            figure.update_layout(title=title.title())\n",
    "        else:\n",
    "            figure.update_layout(title=f'{y_name} by {x_name}<br>Split by {z_name}<br>Rolling Average - {rolling_val}'.replace(\"_\", \" \").title()) \n",
    "\n",
    "        \n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_compare_scatter(best_areas_yearly,\n",
    "                    x_name='date_sold',\n",
    "                    y_name='price',\n",
    "                    z_name='property_type',\n",
    "                    rolling_type='avg',\n",
    "                    rolling_val=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_compare_scatter(best_areas_yearly,\n",
    "                    x_name='date_sold',\n",
    "                    y_name='price',\n",
    "                    z_name='property_type',\n",
    "                    rolling_type='ema',\n",
    "                    ema_val=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regeneration Areas\n",
    "\n",
    "In September 2019 the government announced regeneration projects for a number of towns.\n",
    "\n",
    "<b>df_all_regen_towns</b> is a dataframe with only entries present on the following lists:\n",
    "<ul>\n",
    "    <b><li>regen_towns</li></b>Is a list of ward names of the towns due for regeneration taken from a government press release. \n",
    "    <b><li>guardian_regen_towns</li></b>Is a list of the actual town names themselves, taken from a Guardian article.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('regen.txt') as f:\n",
    "    regen_towns = f.read()\n",
    "    regen_towns = list(regen_towns.split(\"\\n\"))\n",
    "\n",
    "\n",
    "with open('guardian_regen_edit.txt') as f:\n",
    "    guardian_regen_towns = f.read()\n",
    "    guardian_regen_towns = list(guardian_regen_towns.split(\",\"))\n",
    "\n",
    "guardian_regen_towns = [x.lstrip() for x in guardian_regen_towns]\n",
    "\n",
    "df_regen_towns = all_yearly_dataframe.loc[all_yearly_dataframe['ward_name'].isin(regen_towns)]\n",
    "\n",
    "df_guardian_regen_towns = all_yearly_dataframe.loc[all_yearly_dataframe['town/city'].isin(guardian_regen_towns)]\n",
    "\n",
    "df_all_regen_towns = df_regen_towns.append(df_guardian_regen_towns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df_yearly_regen_towns\n",
    "\n",
    "In order to better see the effects of the 2019 announcement, the following line creates a slice of the dataframe containing the entire period. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regen_towns_from_2017 = df_all_regen_towns.loc[df_all_regen_towns['year_sold'] >= 2017]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regen_fig, n_table = expo_subplots_for_area(dataframe=df_regen_towns_from_2017, area='ward_name',\n",
    "                                    target='pct_change',\n",
    "                                    ema_val=0.2,\n",
    "                                    top_n=6)\n",
    "\n",
    "n_table\n",
    "regen_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regen_fig, n_table = expo_subplots_for_area(dataframe=df_regen_towns_from_2017,\n",
    "                                    area='ward_name',\n",
    "                                    target='price',\n",
    "                                    ema_val=0.2,\n",
    "                                    top_n=6)\n",
    "\n",
    "n_table\n",
    "regen_fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# all_regen_plot\n",
    "\n",
    "Similar function as area_sub_plot as above, but plots all lines on the same figure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_regen_plot(dataframe=df_regen_towns_from_2017, target=target, area=area, ema_val=0.5, groupby_option='date_sold'):\n",
    "\n",
    "\n",
    "    year_min = dataframe['year_sold'].min()\n",
    "    year_max = dataframe['year_sold'].max()\n",
    "\n",
    "\n",
    "    n_table = pd.DataFrame(columns=[], index=['n'])\n",
    "\n",
    "    area_list = list(dataframe[area].unique())\n",
    "\n",
    "    #     Creates a figure and axes object.     \n",
    "    fig = make_subplots(rows=1, cols=1)\n",
    "\n",
    "\n",
    "    for location in area_list:\n",
    "        df = dataframe.loc[(dataframe[area] == location) \n",
    "                              & (dataframe['year_sold'] >= year_min) \n",
    "                              & (dataframe['year_sold'] <= year_max)].copy()\n",
    "\n",
    "        df = df.groupby(groupby_option)[target].median().reset_index()\n",
    "\n",
    "        fig.add_trace(go.Scatter(x=df[groupby_option], y=df[target], mode='markers', name='', opacity=0.05))\n",
    "\n",
    "        df['EMA_' + str(ema_val)] = df[target].ewm(alpha=ema_val, adjust=False).mean()\n",
    "\n",
    "        fig.add_trace(go.Scatter(x=df[groupby_option], y=df['EMA_' + str(ema_val)], mode='lines+markers', name=location))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        n_table[location] = len(df)\n",
    "    \n",
    "    fig.update_layout(title_text=f\"Comparison of {target}<br>{area}<br>EMA - {ema_val}\".title().replace(\"_\", \" \"))\n",
    "    fig.update_layout(showlegend=True)\n",
    "    fig.update_xaxes(nticks=15)\n",
    "    fig.update_xaxes(matches='x')\n",
    "\n",
    "\n",
    "    return fig, n_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regen_fig, n_table = all_regen_plot(dataframe=df_regen_towns_from_2017, area='ward_name', target='pct_change', ema_val=0.2)\n",
    "\n",
    "n_table\n",
    "regen_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regen_fig, n_table = all_regen_plot(dataframe=df_regen_towns_from_2017, area='ward_name',\n",
    "                                      target='price',\n",
    "                                      ema_val=0.2)\n",
    "\n",
    "n_table\n",
    "regen_fig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
