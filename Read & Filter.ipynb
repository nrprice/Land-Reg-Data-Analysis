{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r target\n",
    "%store -r area\n",
    "%store -r year_min\n",
    "%store -r year_max\n",
    "%store -r budget_min\n",
    "%store -r budget_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables\n",
      "Target: pct_change\n",
      "area: MSOA\n",
      "year_min: 1995\n",
      "year_max: 2000\n",
      "budget_min: 100000\n",
      "budget_max: 300000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (f'''Variables\n",
    "Target: {target}\n",
    "area: {area}\n",
    "year_min: {year_min}\n",
    "year_max: {year_max}\n",
    "budget_min: {budget_min}\n",
    "budget_max: {budget_max} \\n''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "pd.set_option(\"display.max_rows\", 400000)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of columns from the land registry site\n",
    "column_list = ['TUI',\n",
    "               'price',\n",
    "               'date',\n",
    "               'postcode',\n",
    "               'property_type',\n",
    "               'old/new',\n",
    "               'duration',\n",
    "               'PAON',\n",
    "               'SAON',\n",
    "               'street',\n",
    "               'locality',\n",
    "               'town/city',\n",
    "               'district',\n",
    "               'county',\n",
    "               'ppd_category',\n",
    "               'record_status']\n",
    "\n",
    "post_codes = ['WD', 'EN', 'HA', 'IG', 'RM', 'DA', 'BR', 'CR', 'KT', 'TW', 'UB']\n",
    "london_post_codes = ['E', 'WC', 'EC', 'N', 'NW', 'SE', 'SW', 'W']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read Property Csv\n",
      "Read Postcode Csv\n"
     ]
    }
   ],
   "source": [
    "nrows = 2000000\n",
    "print (\"\\n\")\n",
    "print (\"-\" * 8 + \" Importing csv Data\" + \"-\" * 8)\n",
    "# Reads in the property data CSV\n",
    "main_df = pd.read_csv('pp-complete.csv', names=column_list)\n",
    "print ('read property CSV'.title())\n",
    "\n",
    "# Reads in the postcode data CSV\n",
    "postcode_data = pd.read_csv('National_Statistics_Postcode_Lookup_UK.csv', usecols=['Postcode 1', \n",
    "                                                                                                 'Postcode 2',\n",
    "                                                                                                 'Postcode 3', \n",
    "                                                                                                 'Easting', \n",
    "                                                                                                 'Northing', \n",
    "                                                                                                 'County Name', \n",
    "                                                                                                'Ward Name', \n",
    "                                                                                                'Lower Super Output Area Code', \n",
    "                                                                                                'Lower Super Output Area Name',\n",
    "                                                                                                'Middle Super Output Area Name',\n",
    "                                                                                                'Output Area Classification Name',\n",
    "                                                                                                'Longitude',\n",
    "                                                                                                'Latitude'])\n",
    "print ('read postcode CSV \\n'.title())\n",
    "# renames the useful postcode column to match the convention in the main_df otherwise we can't merge later\n",
    "postcode_data = postcode_data.rename(columns={'Postcode 3': 'postcode'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped Columns\n",
      "Removed Non-Residental Sale Data\n",
      "Converted Prices To Integers\n",
      "Removed Outliers\n",
      "Converted Date_Sold\n",
      "Converted Year\n",
      "Datetime Objects Created\n",
      "Converted Postcodes\n",
      "Removed Nan Values\n",
      "Created Address Column\n",
      "Encoded Categorical Variables\n",
      "Dropped Address Columns\n",
      "Reset Index \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"\\n\")\n",
    "print (\"-\" * 8 + \" Cleaning Data\" + \"-\" * 8)\n",
    "# Drops unneeded columns\n",
    "main_df = main_df.drop(['TUI','district', 'record_status', 'locality', 'county'], axis=1 )\n",
    "print ('Dropped columns'.title())\n",
    "\n",
    "# Removes PPD Category Type 'B' to only leave residental sales\n",
    "main_df = main_df.loc[main_df['ppd_category']  == 'A']\n",
    "print ('removed non-residental sale data'.title())\n",
    "\n",
    "# Converts price to an integer\n",
    "main_df['price'] = main_df['price'].apply(int)\n",
    "print ('Converted prices to integers'.title())\n",
    "\n",
    "# Removes outliers \n",
    "main_df = main_df.loc[(main_df['price'] >= 75000) & (main_df['price'] <= 2000000)]\n",
    "print ('Removed outliers'.title())\n",
    "\n",
    "# Creates a datetime object for the 'date' column, and creates columns for month and year sold. \n",
    "main_df['date_sold'] = pd.to_datetime(main_df['date'], format='%Y-%m-%d %H:%M')\n",
    "print ('converted date_sold'.title())\n",
    "main_df['year_sold'] = main_df['date_sold'].dt.year\n",
    "print ('converted year'.title())\n",
    "# main_df['month_sold'] = main_df['date'].dt.strftime('%m')\n",
    "# print ('converted_month'.title())\n",
    "# main_df['date_sold'] = main_df['date'].dt.strftime('%Y-%m')\n",
    "\n",
    "# Drops unneeded date column\n",
    "main_df = main_df.drop(['date'], axis=1)\n",
    "print ('DateTime objects created'.title())\n",
    "\n",
    "# converts postcodes to strings, and slices just the first two characters\n",
    "main_df['postcode'] = main_df['postcode'].apply(str)\n",
    "# .apply(lambda x: x[:2])\n",
    "# removes the numbers from single digit postcodes \n",
    "# main_df['postcode'] = main_df['postcode'].filter(lambda x: x.isalpha(), x)\n",
    "print ('Converted Postcodes'.title())\n",
    "\n",
    "# Formats the MSOA and LSOA column\n",
    "postcode_data['Middle Super Output Area Name'] = postcode_data['Middle Super Output Area Name'].apply(lambda x: x.replace(\" \", \"\"))\n",
    "postcode_data['Lower Super Output Area Name'] = postcode_data['Lower Super Output Area Name'].apply(lambda x: x.replace(\" \", \"\"))\n",
    "\n",
    "\n",
    "# Fills NaN Values\n",
    "main_df = main_df.fillna(0)\n",
    "print ('Removed NaN Values'.title())\n",
    "\n",
    "# Creates a full address column\n",
    "main_df['address'] = main_df['postcode'].astype(str) + main_df['street'].astype(str) + main_df['SAON'].astype(str) + main_df['PAON'].astype(str)\n",
    "main_df['address'] = main_df['address'].apply(lambda x: x.replace(\" \", \"\"))\n",
    "main_df['address'] = main_df['address'].apply(lambda x: x.lower())\n",
    "print ('Created Address Column')\n",
    "\n",
    "# One hot encodes the old/new categorical feature - 1 is new, 0 is old.\n",
    "main_df['new'] = np.where(main_df['old/new'] == 'Y', 1, 0)\n",
    "# one hot encodes the duration categorical feature - 1 is freehold, 0 is leasehold \n",
    "main_df['freehold'] = np.where(main_df['duration'] == 'F', 1, 0)\n",
    "print ('encoded categorical variables'.title())\n",
    "\n",
    "# Drops unneeded columns\n",
    "main_df = main_df.drop(['PAON', 'SAON', 'street', 'ppd_category', 'old/new', 'duration'], axis=1 )\n",
    "print ('Dropped address columns'.title())\n",
    "\n",
    "\n",
    "\n",
    "main_df = main_df.reset_index(drop=True)\n",
    "print('reset index \\n'.title())\n",
    "\n",
    "# Always ensures that the year we check against is always the most recent available in the dataset\n",
    "# Stops me having to guess the last year when we load in different numbers of rows from the .csv\n",
    "year_to_check = main_df['year_sold'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging Postcode And Property Data\n",
      "Merged Dataframes\n",
      "Saving all_properties_and_postcodes to csv\n",
      "Saved all_properties_and_postcodes \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"\\n\")\n",
    "print (\"-\" * 8 + \"merging postcode and property data\".title() + \"-\" * 8)\n",
    "# Merges postcode and property sale dataframes\n",
    "\n",
    "all_properties_and_postcodes = pd.merge(main_df, postcode_data[['postcode', 'County Name', 'Ward Name', 'Lower Super Output Area Name', 'Middle Super Output Area Name', 'Longitude', 'Latitude']], on='postcode', how='left').sort_values('address')\n",
    "print(\"Merged dataframes\".title())\n",
    "\n",
    "# Renames columns in new dataframe\n",
    "all_properties_and_postcodes = all_properties_and_postcodes.rename(columns={'County Name': 'county_name', 'Ward Name': 'ward_name', 'Lower Super Output Area Name': 'LSOA', 'Middle Super Output Area Name': 'MSOA'})\n",
    "\n",
    "# Saves full_merged_df to a csv file.\n",
    "print ('Saving all_properties_and_postcodes to csv')\n",
    "all_properties_and_postcodes.to_csv('all_properties_and_postcodes.csv')\n",
    "print (\"Saved all_properties_and_postcodes \\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Filtering\n",
      "Saved Filtered_Df \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"\\n\")\n",
    "print (\"-\" * 8 + \"Starting filtering\".title() + \"-\" * 8)\n",
    "\n",
    "# Removes properties not in London or in the surrounding postcodes\n",
    "# main_df = main_df.loc[(main_df['postcode'].apply(lambda x: x[0:2]).isin(post_codes)) | (main_df['town/city'] == 'LONDON')]\n",
    "\n",
    "# Removes any properties sold before the year_min as specified earlier\n",
    "filtered_df = all_properties_and_postcodes.loc[all_properties_and_postcodes['year_sold'] >= year_min]\n",
    "\n",
    "# New Dataframe containing only the address of properties that were in budget for past N years\n",
    "address_df = all_properties_and_postcodes.loc[(all_properties_and_postcodes['price'] > budget_min) &\n",
    "                                (all_properties_and_postcodes['price'] < budget_max) &\n",
    "                                (all_properties_and_postcodes['year_sold'] > (year_to_check - 5))]\n",
    "address_list = list (address_df['address'].values)\n",
    "\n",
    "# Filters properties that are present in address_list\n",
    "filtered_df = filtered_df.loc[filtered_df['address'].isin(address_list)]\n",
    "\n",
    "# Creates a list of properties that have been sold 2 or more times. \n",
    "sold_twice_list = filtered_df[filtered_df['address'].isin(filtered_df['address'].value_counts()[filtered_df['address'].value_counts() >= 2].index)].address\n",
    "\n",
    "# Matches properties in main_df that have been sold twice or more.\n",
    "filtered_df = filtered_df.loc[filtered_df['address'].isin(sold_twice_list)]\n",
    "\n",
    "# Creates a list of properties that have multiple property types \n",
    "multiple_property_type_list = list (filtered_df.groupby('address')['property_type'].nunique()[filtered_df.groupby('address')['property_type'].nunique() >= 2].index)\n",
    "\n",
    "# Removes properties in that list from the final DF\n",
    "filtered_df = filtered_df.loc[~filtered_df['address'].isin(multiple_property_type_list)]\n",
    "\n",
    "# removes any remaining outliers\n",
    "filtered_df = filtered_df.loc[(filtered_df['price'] < budget_max * 1.1) & (filtered_df['price'] > budget_min * 0.85)]\n",
    "\n",
    "filtered_df = filtered_df.reset_index()\n",
    "\n",
    "filtered_df.to_csv('filtered_df.csv')\n",
    "print ('saved filtered_df \\n'.title())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# entire_period_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Groupby\n",
      "Entire_Period_Filtered Dataframe Created\n",
      "Saved Entire_Period_Filtered \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"\\n\")\n",
    "print (\"-\" * 8 + \"starting groupby\".title() + \"-\" * 8)\n",
    "# Creates a total change groupby object that then gets reset into a dataframe\n",
    "\n",
    "entire_period_filtered = filtered_df.groupby(['address', 'property_type', 'postcode', 'county_name', 'ward_name', 'town/city', 'LSOA', 'MSOA']).agg(min_price=('price', 'min'),\n",
    "                                                                              year_sold_min=('date_sold', 'min'),\n",
    "                                                                              max_price=('price', 'max'),\n",
    "                                                                              year_sold_max=('date_sold', 'max'),\n",
    "                                                                              price_diff=('price', lambda x: (x.max() - x.min())),\n",
    "                                                                              year_diff=('date_sold', lambda x: (((x.max() - x.min()).days) / 365)))\n",
    "\n",
    "entire_period_filtered = entire_period_filtered.reset_index()\n",
    "print ('entire_period_filtered dataframe created'.title())\n",
    "\n",
    "# Removes any entries that were sold in the same year or had their value increase\n",
    "entire_period_filtered = entire_period_filtered.loc[(entire_period_filtered['price_diff'] != 0) & (entire_period_filtered['year_diff'] >= 1)]\n",
    "\n",
    "# Number of decimal places in round()\n",
    "n = 2\n",
    "\n",
    "# Rounds the years diff column value to 2 decimal places\n",
    "# Not possible to do within the .agg function it seems\n",
    "entire_period_filtered['year_diff'] = entire_period_filtered['year_diff'].round(n)\n",
    "\n",
    "# Total price change per year\n",
    "entire_period_filtered['price_change_per_year'] = (entire_period_filtered['price_diff'] / entire_period_filtered['year_diff']).round(n)\n",
    "\n",
    "# Total percentage change\n",
    "entire_period_filtered['pct_change'] = ((((entire_period_filtered['max_price'] - entire_period_filtered['min_price']) / entire_period_filtered['min_price']) * 100)).round(n)\n",
    "\n",
    "# Percentage change per year\n",
    "entire_period_filtered['pct_change_per_year'] = (entire_period_filtered['pct_change'] / entire_period_filtered['year_diff']).round(n)\n",
    "\n",
    "entire_period_filtered.to_csv('entire_period_filtered.csv')\n",
    "print ('saved entire_period_filtered \\n'.title())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
